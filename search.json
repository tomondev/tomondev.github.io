[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Tom. I like to write about various interesting topics.\nIf you find mistakes in my posts, please file issues."
  },
  {
    "objectID": "posts/spherical-harmonics/index.html",
    "href": "posts/spherical-harmonics/index.html",
    "title": "Spherical Harmonics: Visualization and Applications",
    "section": "",
    "text": "In the example of 2D Gaussian Splatting, we use a vector \\(c\\in\\mathbb{R}^3\\) to represent the color of a 2D Gaussian. In the 2D case, a Gaussian shows the same color regardless of the viewing direction. In 3D Gaussian Splatting (3DGS), however, it is common to model view-dependent appearance (e.g., Lambertian or glossy surfaces). Therefore, we cannot assign fixed RGB values to each 3D Gaussian, because the color must change based on the viewer’s perspective.\nIntuitively, modeling arbitrary view-dependent appearance requires defining a function on the surface of a sphere. While a straightforward approach is to discretize the sphere with a grid and assign a value to each cell, this method introduces a prohibitive number of parameters for each Gaussian—not to mention that we may have tens of thousands of Gaussians in a scene.\nA natural approach is to parameterize the spherical function using a set of basis functions. Just as one-dimensional periodic functions on a circle can be expressed as a sum of circular functions (sines and cosines) via Fourier series, spherical functions can be represented as a sum of spherical harmonics, which are a set of orthogonal functions defined on the surface of a sphere."
  },
  {
    "objectID": "posts/spherical-harmonics/index.html#references",
    "href": "posts/spherical-harmonics/index.html#references",
    "title": "Spherical Harmonics: Visualization and Applications",
    "section": "References",
    "text": "References\n\n3D Gaussian Splatting for Real-Time Radiance Field Rendering\nPlenOctrees for Real-time Rendering of Neural Radiance Fields\nSpherical Harmonic Lighting: The Gritty Details"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "On Notes",
    "section": "",
    "text": "Date\n\n\n\nPosts\n\n\n\n\n\n\n\n\nFebruary, 2025\n\n\nSpherical Harmonics: Visualization and Applications\n\n\n\n\n\n\nJanuary, 2025\n\n\n2D Gaussian Splatting and Image Rendering\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/image-2dgs/index.html",
    "href": "posts/image-2dgs/index.html",
    "title": "2D Gaussian Splatting and Image Rendering",
    "section": "",
    "text": "3D Gaussian Splatting (3DGS) is a rendering technique for photorealistic view synthesis. In this post, we create a toy example of 2D Gaussian splatting (2DGS). We train a 2DGS model to render a small image. This 2D version removes much of the complexity found in 3DGS, making the core ideas easier to understand.\nHere are some key differences between 2DGS and 3DGS:"
  },
  {
    "objectID": "posts/image-2dgs/index.html#problem-formulation",
    "href": "posts/image-2dgs/index.html#problem-formulation",
    "title": "2D Gaussian Splatting and Image Rendering",
    "section": "Problem Formulation",
    "text": "Problem Formulation\nA 2D Gaussian has a mean vector \\(\\mu\\in\\mathbb{R}^2\\) and a covariance matrix \\(\\Sigma\\in\\mathbb{R}^{2 \\times 2}\\). The density is \\[\nG(x)=\\exp\\left(-\\dfrac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right),\n\\] where \\(x\\) is the pixel location. This is not a probability density, so it does not need to be normalized.\nA common parameterization uses \\(\\Sigma = R S S^T R^T\\) to ensure \\(\\Sigma\\) is always positive semi-definite during training. \\(R\\in\\mathbb{R}^{2\\times2}\\) is a rotation matrix parameterized by an angle \\(\\theta\\in[0,\\pi]\\), and \\(S\\in\\mathbb{R}^{2\\times2}\\) is a scaling matrix determined by a scaling vector \\(s\\in\\mathbb{R}^2_+\\).\nNext, we assign a color to each Gaussian. Unlike 3DGS, which uses spherical harmonics, we only need a vector \\(c\\in\\mathbb{R}^3\\) to represent RGB values.\nThus, a 2D Gaussian primitive is characterized by \\((\\mu, \\theta, s, c)\\). Each pixel value \\(\\mathbf{RGB}(x)\\) is a weighted average of all Gaussians, with weights given by \\(G_i(x)\\): \\[\n\\mathbf{RGB}(x)=\\dfrac{1}{\\sum_i G_i(x)}\\sum_i G_i(x)c_i.\n\\]"
  },
  {
    "objectID": "posts/image-2dgs/index.html#implementation",
    "href": "posts/image-2dgs/index.html#implementation",
    "title": "2D Gaussian Splatting and Image Rendering",
    "section": "Implementation",
    "text": "Implementation\nFirst, we randomly initialize all Gaussian parameters. We use 5000 Gaussians. Using more Gaussians improves quality but increases memory usage.\n_GS_NUM = 5000\nkey = jax.random.PRNGKey(0)\nkey_mu, key_theta, key_scaling, key_color = jax.random.split(key, 4)\nmu_array = jax.random.uniform(key_mu, (_GS_NUM, 2), minval=0.0, maxval=1.0)\ntheta_array = jax.random.uniform(key_theta, (_GS_NUM, 1), minval=0.0, maxval=jnp.pi)\nscaling_array = jax.random.uniform(\n    key_scaling, (_GS_NUM, 2), minval=0.0, maxval=0.1\n)\ncolor_array = jax.random.uniform(key_color, (_GS_NUM, 3), minval=0.0, maxval=255.0)\nNext, we implement the key part of the training code: a function to compute the Gaussian density. We implement the function for a single Gaussian at a single pixel location, then use three layers of jax.vmap to vectorize it so one call computes the density for all Gaussians at all locations.\n@partial(jax.vmap, in_axes=(None, None, None, 0))  # map over height\n@partial(jax.vmap, in_axes=(None, None, None, 0))  # map over width\n@partial(jax.vmap, in_axes=(0, 0, 0, None))        # map over Gaussians\ndef compute_gaussians(mu, theta, scaling, coord):\n    \"\"\"Compute the value of a single Gaussian at the given coordinate.\"\"\"\n    # rotation matrix\n    theta = jnp.clip(theta, 0.0, jnp.pi)\n    c = jnp.cos(theta[0])\n    s = jnp.sin(theta[0])\n    R = jnp.array([[c, -s], [s, c]])\n    # scaling matrix\n    scaling = jnp.clip(scaling, min=1e-6)\n    S = jnp.diag(scaling)\n    # covariance matrix\n    Sigma = R @ S @ S @ R.T + 1e-6 * jnp.eye(2)\n    diff = coord - mu\n    exponent = -0.5 * diff @ jnp.linalg.inv(Sigma) @ diff.T\n    return jnp.exp(exponent)\nWith compute_gaussians implemented, we finish the rendering function. It computes a weighted average of all Gaussian colors for each pixel. @jax.jit compiles and accelerates the call.\n@jax.jit\ndef render_image(mu_array, theta_array, scaling_array, color_array, coords):\n    \"\"\"Render the image from the parameters.\"\"\"\n    gaussians = compute_gaussians(mu_array, theta_array, scaling_array, coords)\n    # weighted average of gaussians\n    rendered_image = jnp.matmul(gaussians, color_array) / (\n        jnp.sum(gaussians, axis=-1, keepdims=True) + 1e-6\n    )\n    return jnp.clip(rendered_image, 0, 255)\nThe image below illustrates the rendering of two random Gaussians. Notice how the colors blend at the intersection. High-quality image rendering typically uses tens of thousands of Gaussians.\n\nThe function render_image is differentiable. We compute the loss by comparing the reconstructed image with the target image. Either \\(L_1\\) loss or MSE works. It is straightforward to implement the training loop in the main function. Summary:\n\nInitialize the Gaussians\nLoop:\n\nRender the image\nCompute L1 loss and gradients\nUpdate Gaussian parameters\n\n\n_SIZE = 128\n_ITERATIONS = 1000\n_GS_INITIAL_NUM = 5000\n\ndef main():\n    img = Image.open(\"input.jpg\")\n    img_array = np.array(img)\n    key = jax.random.PRNGKey(0)\n    key_mu, key_theta, key_scaling, key_color = jax.random.split(key, 4)\n    mu_array = jax.random.uniform(key_mu, (_GS_NUM, 2), minval=0.0, maxval=1.0)\n    theta_array = jax.random.uniform(key_theta, (_GS_NUM, 1), minval=0.0, maxval=jnp.pi)\n    scaling_array = jax.random.uniform(\n        key_scaling, (_GS_NUM, 2), minval=0.0, maxval=0.1\n    )\n    color_array = jax.random.uniform(key_color, (_GS_NUM, 3), minval=0.0, maxval=255.0)\n\n    # create a grid of x, y coordinates\n    x = jnp.linspace(0, 1.0, _SIZE)\n    y = jnp.linspace(0, 1.0, _SIZE)\n    xx, yy = jnp.meshgrid(x, y)\n    coords = jnp.stack([xx, yy], axis=-1)  # shape (_SIZE, _SIZE, 2)\n\n    learning_rate = 0.001\n    optimizer = optax.adam(learning_rate)\n    params = (mu_array, theta_array, scaling_array, color_array)\n    opt_state = optimizer.init(params)\n\n    def loss_fn(params):\n        rendered = render_image(\n            *params,\n            coords,\n        )\n        return jnp.mean(jnp.abs(rendered - img_array))\n\n    def update(params, opt_state):\n        grads = jax.grad(loss_fn)(params)\n        updates, opt_state = optimizer.update(grads, opt_state)\n        new_params = optax.apply_updates(params, updates)\n        return new_params, opt_state\n\n    for i in range(_ITERATIONS):\n        params, opt_state = update(params, opt_state)\n        current_loss = loss_fn(params)\nYou can find the complete code here:"
  },
  {
    "objectID": "posts/image-2dgs/index.html#target-image",
    "href": "posts/image-2dgs/index.html#target-image",
    "title": "2D Gaussian Splatting and Image Rendering",
    "section": "Target Image",
    "text": "Target Image\nHere is the target image (128×128):"
  },
  {
    "objectID": "posts/image-2dgs/index.html#results",
    "href": "posts/image-2dgs/index.html#results",
    "title": "2D Gaussian Splatting and Image Rendering",
    "section": "Results",
    "text": "Results\nThe first image is the target image. The last image is from iteration 1000.\n\n\nAnimation"
  },
  {
    "objectID": "posts/image-2dgs/index.html#important-notes",
    "href": "posts/image-2dgs/index.html#important-notes",
    "title": "2D Gaussian Splatting and Image Rendering",
    "section": "Important Notes",
    "text": "Important Notes\nThe current implementation is inefficient and overly simplistic. Improvements can be made in the following areas:\nTo enhance efficiency, we can avoid evaluating all Gaussians for every pixel. Gaussians far from a pixel contribute negligibly to its color. A more efficient approach would be to select the K Gaussians with the highest density at a pixel. However, identifying and managing K Gaussians per pixel may be too resource-intensive. A pragmatic solution is to generate K Gaussians per tile, while ensuring Gaussians spanning multiple tiles are handled properly.\nRandom initialization is not optimal. We can initialize Gaussian geometry and color based on pixel intensity and gradients in the target image. This likely leads to faster convergence and better reconstruction quality.\nThe number of Gaussians does not need to be fixed. In each iteration, we can remove Gaussians whose contributions are negligible and create new ones at pixels with high reconstruction error.\nIn summary, this is a basic example illustrating how Gaussian splatting works. Many improvements can be implemented to render a high-quality image more efficiently."
  }
]