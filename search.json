[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "On Notes",
    "section": "",
    "text": "Date\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nAug 1, 2025\n\n\nA Toy Example of 2D Gaussian Splatting in JAX\n\n\nTom \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/image-2dgs/index.html",
    "href": "posts/image-2dgs/index.html",
    "title": "A Toy Example of 2D Gaussian Splatting in JAX",
    "section": "",
    "text": "3D Gaussian Splatting (3DGS) is a rendering technique for photorealistic view synthesis. In this post, we will create a toy example of 2D Gaussian splatting (2DGS). We will train a 2DGS model to render a small image. This 2D version strips away much of the complexity found in 3DGS, making the core ideas much easier to understand.\nHere are some key differences between 2DGS and 3DGS:"
  },
  {
    "objectID": "posts/image-2dgs/index.html#problem-formulation",
    "href": "posts/image-2dgs/index.html#problem-formulation",
    "title": "A Toy Example of 2D Gaussian Splatting in JAX",
    "section": "Problem Formulation",
    "text": "Problem Formulation\nA 2D Gaussian has a mean vector \\(\\mu\\in\\mathbb{R}^2\\) and a covariance matrix \\(\\Sigma\\in\\mathbb{R}^{2 \\times 2}\\). The density is expressed as \\[\nG(x)=\\exp\\left(-\\dfrac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)\n\\] where \\(x\\) is the pixel location. Note that this is not a probability density, so it doesn’t need to be normalized.\nUsually, people use \\(\\Sigma=RSS^TR^T\\) to ensure \\(\\Sigma\\) is always positive semi-definite during training. \\(R\\in\\mathbb{R}^{2\\times2}\\) is a rotation matrix, and \\(S\\in\\mathbb{R}^{2\\times2}\\) is a scaling matrix. \\(R\\) is parameterized by an angle \\(\\theta\\in[0,\\pi]\\), and \\(S\\) is determined by a scaling vector \\(s\\in\\mathbb{R}^2_+\\).\nLastly, we need to assign a color to each Gaussian. Unlike 3DGS, which uses spherical harmonics, we only need a vector \\(c\\in\\mathbb{R}^3\\) to represent the RGB values of a 2D Gaussian.\nTo summarize, each 2D Gaussian primitive is characterized by \\((\\mu, \\theta, s, c)\\). Each pixel value \\(\\mathbf{RGB}(x)\\) is determined by a weighted average of all the Gaussians where the weights are computed by the density function \\(G(x)\\): \\[\n\\mathbf{RGB}(x)=\\dfrac{1}{\\sum_i G_i(x)}\\sum_i G_i(x)c_i\n\\]"
  },
  {
    "objectID": "posts/image-2dgs/index.html#target-image",
    "href": "posts/image-2dgs/index.html#target-image",
    "title": "A Toy Example of 2D Gaussian Splatting in JAX",
    "section": "Target Image",
    "text": "Target Image\nHere is our target image with a size of 128x128."
  },
  {
    "objectID": "posts/image-2dgs/index.html#implementation",
    "href": "posts/image-2dgs/index.html#implementation",
    "title": "A Toy Example of 2D Gaussian Splatting in JAX",
    "section": "Implementation",
    "text": "Implementation\nFirst, we randomly initialize all the Gaussian parameters. We use a total of 5000 Gaussians. Using more Gaussians improves quality but also increases memory usage.\n_GS_NUM = 5000\nkey = jax.random.PRNGKey(0)\nkey_mu, key_theta, key_scaling, key_color = jax.random.split(key, 4)\nmu_array = jax.random.uniform(key_mu, (_GS_NUM, 2), minval=0.0, maxval=1.0)\ntheta_array = jax.random.uniform(key_theta, (_GS_NUM, 1), minval=0.0, maxval=jnp.pi)\nscaling_array = jax.random.uniform(\n    key_scaling, (_GS_NUM, 2), minval=0.0, maxval=0.1\n)\ncolor_array = jax.random.uniform(key_color, (_GS_NUM, 3), minval=0.0, maxval=255.0)\nNext, we implement the key part of the training code: a function to compute the Gaussian density. We will implement the function for computing the density of a single Gaussian at a single pixel location. We then use three layers of jax.vmap to vectorize the function, allowing a single call to compute the density for all Gaussians at all locations.\n@partial(jax.vmap, in_axes=(None, None, None, 0))  # map over height dimension\n@partial(jax.vmap, in_axes=(None, None, None, 0))  # map over width dimension\n@partial(jax.vmap, in_axes=(0, 0, 0, None))  # map over gaussians\ndef compute_gaussians(mu, theta, scaling, coord):\n    \"\"\"Compute the value of a single Gaussian at the given coordinate.\"\"\"\n    # rotation matrix\n    # clip theta to the range [0, pi]\n    theta = jnp.clip(theta, 0.0, jnp.pi)\n    c = jnp.cos(theta[0])\n    s = jnp.sin(theta[0])\n    R = jnp.array([[c, -s], [s, c]])\n    # scaling matrix\n    # clip scaling to be positive\n    scaling = jnp.clip(scaling, min=1e-6, max=None)\n    S = jnp.diag(scaling)\n    # covariance matrix\n    # add small value for numerical stability\n    Sigma = R @ S @ S @ R.T + 1e-6 * jnp.eye(2)\n    diff = coord - mu\n    exponent = -0.5 * diff @ jnp.linalg.inv(Sigma) @ diff.T\n    return jnp.exp(exponent)\nWith compute_gaussians implemented, it is easy to finish the rendering function. It basically computes a weighted average of all Gaussian colors for each pixel. @jax.jit is needed to compile and accelerate the rendering call.\n@jax.jit\ndef render_image(mu_array, theta_array, scaling_array, color_array, coords):\n    \"\"\"Render the image from the parameters.\"\"\"\n    gaussians = compute_gaussians(mu_array, theta_array, scaling_array, coords)\n    # weighted average of gaussians\n    rendered_image = jnp.matmul(gaussians, color_array) / (\n        jnp.sum(gaussians, axis=-1, keepdims=True) + 1e-6\n    )\n    rendered_image = jnp.clip(rendered_image, 0, 255)\n    return rendered_image\nWith all the code above, it is now straightforward to implement the training loop in the main function. We can summarize the training code as follows:\n\nInitialize the gaussians\nloop\n\nrender the image\ncompute l1 loss and gradients\nupdate gaussian parameters\n\n\n_SIZE = 128\n_ITERATIONS = 1000\n_GS_INITIAL_NUM = 5000\n\ndef main():\n    img = Image.open(\"input.jpg\")\n    img_array = np.array(img)\n    key = jax.random.PRNGKey(0)\n    key_mu, key_theta, key_scaling, key_color = jax.random.split(key, 4)\n    mu_array = jax.random.uniform(key_mu, (_GS_NUM, 2), minval=0.0, maxval=1.0)\n    theta_array = jax.random.uniform(key_theta, (_GS_NUM, 1), minval=0.0, maxval=jnp.pi)\n    scaling_array = jax.random.uniform(\n        key_scaling, (_GS_NUM, 2), minval=0.0, maxval=0.1\n    )\n    color_array = jax.random.uniform(key_color, (_GS_NUM, 3), minval=0.0, maxval=255.0)\n\n    # create a grid of x, y coordinates\n    x = jnp.linspace(0, 1.0, _SIZE)\n    y = jnp.linspace(0, 1.0, _SIZE)\n    xx, yy = jnp.meshgrid(x, y)\n    coords = jnp.stack([xx, yy], axis=-1)  # shape (_SIZE, _SIZE, 2)\n\n    learning_rate = 0.001\n    optimizer = optax.adam(learning_rate)\n    params = (mu_array, theta_array, scaling_array, color_array)\n    opt_state = optimizer.init(params)\n\n    def loss_fn(params):\n        rendered = render_image(\n            *params,\n            coords,\n        )\n        return jnp.mean(jnp.abs(rendered - img_array))\n\n    def update(params, opt_state):\n        grads = jax.grad(loss_fn)(params)\n        updates, opt_state = optimizer.update(grads, opt_state)\n        new_params = optax.apply_updates(params, updates)\n        return new_params, opt_state\n\n    for i in range(_ITERATIONS):\n        params, opt_state = update(params, opt_state)\n        current_loss = loss_fn(params)\nPlease see the complete code in this repo."
  },
  {
    "objectID": "posts/image-2dgs/index.html#results",
    "href": "posts/image-2dgs/index.html#results",
    "title": "A Toy Example of 2D Gaussian Splatting in JAX",
    "section": "Results",
    "text": "Results\nThe first image is the target image. The last image is from iteration 1000.\n\n\nanimation"
  },
  {
    "objectID": "posts/image-2dgs/index.html#important-notes",
    "href": "posts/image-2dgs/index.html#important-notes",
    "title": "A Toy Example of 2D Gaussian Splatting in JAX",
    "section": "Important Notes",
    "text": "Important Notes\nThe current implementation is inefficient and overly simplistic. Improvements can be made in the following aspects:\nTo enhance efficiency, we can avoid evaluating all Gaussians for every pixel. Gaussians located far from a pixel contribute negligibly to its color. A more efficient approach involves selecting the K Gaussians with the highest density at a given pixel. However, identifying and managing K Gaussians for each individual pixel might be too resource-intensive. A more pragmatic solution is to generate K Gaussians for a specific tile, while ensuring that Gaussians spanning multiple tiles are managed appropriately.\nIt is not optimal to initialize the Gaussians randomly. Instead, we can initialize the geometry and color of the Gaussians according to pixel intensity and gradients. This will likely lead to faster convergence and better reconstruction quality.\nLast but not least, the number of Gaussians doesn’t have to be fixed. In each iteration, we can remove some Gaussians whose contributions are negligible and create new Gaussians at pixels where reconstruction errors are high.\nTo summarize, this is a basic example that illustrates how Gaussian splatting works. Many improvements can be added to render a high-quality image more efficiently."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My name is Tom. I write small examples on various interesting topics.\nIf you find mistakes in my posts, please file issues."
  }
]